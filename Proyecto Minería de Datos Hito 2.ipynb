{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto Mineria de Datos\n",
    "## Hito 2\n",
    "### Integrantes\n",
    "\n",
    "Ignacio Basualto, Raimundo Vicente, Renato Cerda, Sebastián Bustos y  Diego Olguín\n",
    "\n",
    "Elección de base de datos elegida gira entorno al tema: \"Caracterizar series de anime\". El dataset utilizado se encuentra en [link](https://www.kaggle.com/azathoth42/myanimelist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aqui agregar lo del hito 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aqui agregar lo que haremos en el hito 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>user_watching</th>\n",
       "      <th>user_completed</th>\n",
       "      <th>user_onhold</th>\n",
       "      <th>user_dropped</th>\n",
       "      <th>user_plantowatch</th>\n",
       "      <th>user_days_spent_watching</th>\n",
       "      <th>gender</th>\n",
       "      <th>birth_date</th>\n",
       "      <th>join_date</th>\n",
       "      <th>last_online</th>\n",
       "      <th>stats_mean_score</th>\n",
       "      <th>stats_rewatched</th>\n",
       "      <th>stats_episodes</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>karthiga</td>\n",
       "      <td>3</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55.091667</td>\n",
       "      <td>Female</td>\n",
       "      <td>1990-04-29</td>\n",
       "      <td>2013-03-03</td>\n",
       "      <td>2014-02-04</td>\n",
       "      <td>7.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3391</td>\n",
       "      <td>India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Damonashu</td>\n",
       "      <td>45</td>\n",
       "      <td>195</td>\n",
       "      <td>27</td>\n",
       "      <td>25</td>\n",
       "      <td>59</td>\n",
       "      <td>82.574306</td>\n",
       "      <td>Male</td>\n",
       "      <td>1991-08-01</td>\n",
       "      <td>2008-02-13</td>\n",
       "      <td>2017-07-10</td>\n",
       "      <td>6.15</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4903</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bskai</td>\n",
       "      <td>25</td>\n",
       "      <td>414</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>159.483333</td>\n",
       "      <td>Male</td>\n",
       "      <td>1990-12-14</td>\n",
       "      <td>2009-08-31</td>\n",
       "      <td>2014-05-12</td>\n",
       "      <td>8.27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9701</td>\n",
       "      <td>México</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>terune_uzumaki</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.394444</td>\n",
       "      <td>Female</td>\n",
       "      <td>1998-08-24</td>\n",
       "      <td>2010-05-10</td>\n",
       "      <td>2012-10-18</td>\n",
       "      <td>9.70</td>\n",
       "      <td>6.0</td>\n",
       "      <td>697</td>\n",
       "      <td>Malaysia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bas_G</td>\n",
       "      <td>35</td>\n",
       "      <td>114</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>175</td>\n",
       "      <td>30.458333</td>\n",
       "      <td>Male</td>\n",
       "      <td>1999-10-24</td>\n",
       "      <td>2015-11-26</td>\n",
       "      <td>2018-05-10</td>\n",
       "      <td>7.86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1847</td>\n",
       "      <td>Nederland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108700</th>\n",
       "      <td>isoann</td>\n",
       "      <td>14</td>\n",
       "      <td>213</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>136</td>\n",
       "      <td>64.372222</td>\n",
       "      <td>Male</td>\n",
       "      <td>1997-01-13</td>\n",
       "      <td>2011-10-23</td>\n",
       "      <td>2018-02-25</td>\n",
       "      <td>8.03</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3939</td>\n",
       "      <td>RP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108701</th>\n",
       "      <td>bumcakee</td>\n",
       "      <td>13</td>\n",
       "      <td>116</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "      <td>41.365972</td>\n",
       "      <td>Female</td>\n",
       "      <td>1998-07-18</td>\n",
       "      <td>2012-07-14</td>\n",
       "      <td>2017-02-14</td>\n",
       "      <td>8.86</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2537</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108702</th>\n",
       "      <td>Scarlet95</td>\n",
       "      <td>6</td>\n",
       "      <td>103</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>54</td>\n",
       "      <td>46.827083</td>\n",
       "      <td>Female</td>\n",
       "      <td>1995-10-17</td>\n",
       "      <td>2013-04-24</td>\n",
       "      <td>2016-12-18</td>\n",
       "      <td>7.40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2869</td>\n",
       "      <td>België / Belgique / Belgien</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108703</th>\n",
       "      <td>Torasori</td>\n",
       "      <td>22</td>\n",
       "      <td>239</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>176</td>\n",
       "      <td>72.361111</td>\n",
       "      <td>Male</td>\n",
       "      <td>1998-11-18</td>\n",
       "      <td>2014-07-30</td>\n",
       "      <td>2018-05-24</td>\n",
       "      <td>8.98</td>\n",
       "      <td>47.0</td>\n",
       "      <td>4469</td>\n",
       "      <td>Latvija</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108704</th>\n",
       "      <td>HMicca</td>\n",
       "      <td>11</td>\n",
       "      <td>73</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>64.431250</td>\n",
       "      <td>Female</td>\n",
       "      <td>1995-08-12</td>\n",
       "      <td>2012-05-05</td>\n",
       "      <td>2012-11-15</td>\n",
       "      <td>8.89</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3822</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108705 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              username  user_watching  user_completed  user_onhold  \\\n",
       "0             karthiga              3              49            1   \n",
       "1            Damonashu             45             195           27   \n",
       "2                bskai             25             414            2   \n",
       "3       terune_uzumaki              5               5            0   \n",
       "4                Bas_G             35             114            6   \n",
       "...                ...            ...             ...          ...   \n",
       "108700          isoann             14             213           11   \n",
       "108701        bumcakee             13             116            5   \n",
       "108702       Scarlet95              6             103           10   \n",
       "108703        Torasori             22             239            0   \n",
       "108704          HMicca             11              73            2   \n",
       "\n",
       "        user_dropped  user_plantowatch  user_days_spent_watching  gender  \\\n",
       "0                  0                 0                 55.091667  Female   \n",
       "1                 25                59                 82.574306    Male   \n",
       "2                  5                11                159.483333    Male   \n",
       "3                  0                 0                 11.394444  Female   \n",
       "4                 20               175                 30.458333    Male   \n",
       "...              ...               ...                       ...     ...   \n",
       "108700            20               136                 64.372222    Male   \n",
       "108701             9                22                 41.365972  Female   \n",
       "108702             8                54                 46.827083  Female   \n",
       "108703             4               176                 72.361111    Male   \n",
       "108704             2                16                 64.431250  Female   \n",
       "\n",
       "        birth_date   join_date last_online  stats_mean_score  stats_rewatched  \\\n",
       "0       1990-04-29  2013-03-03  2014-02-04              7.43              0.0   \n",
       "1       1991-08-01  2008-02-13  2017-07-10              6.15              6.0   \n",
       "2       1990-12-14  2009-08-31  2014-05-12              8.27              1.0   \n",
       "3       1998-08-24  2010-05-10  2012-10-18              9.70              6.0   \n",
       "4       1999-10-24  2015-11-26  2018-05-10              7.86              0.0   \n",
       "...            ...         ...         ...               ...              ...   \n",
       "108700  1997-01-13  2011-10-23  2018-02-25              8.03              2.0   \n",
       "108701  1998-07-18  2012-07-14  2017-02-14              8.86             24.0   \n",
       "108702  1995-10-17  2013-04-24  2016-12-18              7.40              1.0   \n",
       "108703  1998-11-18  2014-07-30  2018-05-24              8.98             47.0   \n",
       "108704  1995-08-12  2012-05-05  2012-11-15              8.89             11.0   \n",
       "\n",
       "        stats_episodes                      country  \n",
       "0                 3391                        India  \n",
       "1                 4903                          USA  \n",
       "2                 9701                       México  \n",
       "3                  697                     Malaysia  \n",
       "4                 1847                    Nederland  \n",
       "...                ...                          ...  \n",
       "108700            3939                           RP  \n",
       "108701            2537                          NaN  \n",
       "108702            2869  België / Belgique / Belgien  \n",
       "108703            4469                      Latvija  \n",
       "108704            3822                           UK  \n",
       "\n",
       "[108705 rows x 15 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>anime_id</th>\n",
       "      <th>my_watched_episodes</th>\n",
       "      <th>my_start_date</th>\n",
       "      <th>my_finish_date</th>\n",
       "      <th>my_score</th>\n",
       "      <th>my_status</th>\n",
       "      <th>my_rewatching</th>\n",
       "      <th>my_rewatching_ep</th>\n",
       "      <th>my_last_updated</th>\n",
       "      <th>my_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>karthiga</td>\n",
       "      <td>21</td>\n",
       "      <td>586</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-03-03 10:52:53</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>karthiga</td>\n",
       "      <td>59</td>\n",
       "      <td>26</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-03-10 13:54:51</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>karthiga</td>\n",
       "      <td>74</td>\n",
       "      <td>26</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-04-27 16:43:35</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>karthiga</td>\n",
       "      <td>120</td>\n",
       "      <td>26</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-03-03 10:53:57</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>karthiga</td>\n",
       "      <td>178</td>\n",
       "      <td>26</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-03-27 15:59:13</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31284025</th>\n",
       "      <td>Yokonightcore</td>\n",
       "      <td>15611</td>\n",
       "      <td>48</td>\n",
       "      <td>2014-00-00</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-09-07 17:33:03</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31284026</th>\n",
       "      <td>Yokonightcore</td>\n",
       "      <td>27815</td>\n",
       "      <td>22</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-09-07 17:32:05</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31284027</th>\n",
       "      <td>wargod</td>\n",
       "      <td>5945</td>\n",
       "      <td>39</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-03-29 04:24:12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31284028</th>\n",
       "      <td>JMc_SetoKai_LoVe</td>\n",
       "      <td>1316</td>\n",
       "      <td>52</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2009-12-23 05:45:14</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31284029</th>\n",
       "      <td>hinogurl_mikha</td>\n",
       "      <td>1744</td>\n",
       "      <td>58</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-04-05 11:36:20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31284030 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  username  anime_id  my_watched_episodes my_start_date  \\\n",
       "0                 karthiga        21                  586    0000-00-00   \n",
       "1                 karthiga        59                   26    0000-00-00   \n",
       "2                 karthiga        74                   26    0000-00-00   \n",
       "3                 karthiga       120                   26    0000-00-00   \n",
       "4                 karthiga       178                   26    0000-00-00   \n",
       "...                    ...       ...                  ...           ...   \n",
       "31284025     Yokonightcore     15611                   48    2014-00-00   \n",
       "31284026     Yokonightcore     27815                   22    0000-00-00   \n",
       "31284027            wargod      5945                   39    0000-00-00   \n",
       "31284028  JMc_SetoKai_LoVe      1316                   52    0000-00-00   \n",
       "31284029    hinogurl_mikha      1744                   58    0000-00-00   \n",
       "\n",
       "         my_finish_date  my_score  my_status  my_rewatching  my_rewatching_ep  \\\n",
       "0            0000-00-00         9          1            NaN                 0   \n",
       "1            0000-00-00         7          2            NaN                 0   \n",
       "2            0000-00-00         7          2            NaN                 0   \n",
       "3            0000-00-00         7          2            NaN                 0   \n",
       "4            0000-00-00         7          2            0.0                 0   \n",
       "...                 ...       ...        ...            ...               ...   \n",
       "31284025     0000-00-00         9          1            NaN                 0   \n",
       "31284026     0000-00-00         9          1            NaN                 0   \n",
       "31284027     0000-00-00         8          2            0.0                 0   \n",
       "31284028     0000-00-00         9          2            NaN                 0   \n",
       "31284029     0000-00-00        10          1            0.0                 0   \n",
       "\n",
       "              my_last_updated my_tags  \n",
       "0         2013-03-03 10:52:53     NaN  \n",
       "1         2013-03-10 13:54:51     NaN  \n",
       "2         2013-04-27 16:43:35     NaN  \n",
       "3         2013-03-03 10:53:57     NaN  \n",
       "4         2013-03-27 15:59:13     NaN  \n",
       "...                       ...     ...  \n",
       "31284025  2015-09-07 17:33:03     NaN  \n",
       "31284026  2015-09-07 17:32:05     NaN  \n",
       "31284027  2010-03-29 04:24:12     NaN  \n",
       "31284028  2009-12-23 05:45:14     NaN  \n",
       "31284029  2008-04-05 11:36:20     NaN  \n",
       "\n",
       "[31284030 rows x 11 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userAnimeList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimento 1 (Clustering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimento 2 (Predicción de identidad de genero)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para responder la pregunta si es posible predecir la identidad de genero de un usuario dado sus caracteristicas y animes vistos. Para esto se propone la siguiente metodologia.\n",
    "\n",
    "El dataset esta dividido en tres partes luego y cada uno es más especifico que el otro, luego haremos un preprocesamiento de la información que nos permita tener tres datasets que estudiar\n",
    "\n",
    "* userList\n",
    "* userList + userAnimeList\n",
    "* userList + userAnimeList + animeList\n",
    "\n",
    "De esta forma la información partira simple y se empezara complejizando, se espera que separar asi la información entrege una mayor interpretabilidad de los modelos.\n",
    "\n",
    "En los tres dataset todavía existen variables categorícas, las que no entreguen información se van a eliminar y las que (potencialmente) lo hagan se van ya sea transformar a numeros o aplicar algun metodo como OHE, es importante notar que columnas como username son necesarias pues es la forma de poder unir todos los dataframes, al momento de hacer predicciones se eliminaran.\n",
    "\n",
    "Como nos interesa realizar predicciones realizaremos el desarrollo y enfoque en eso. Para identidad de genero se presentan clases desbalancedas, por el momento se mantendra el desbalanceo como parte de la información.\n",
    "\n",
    "A continuación se pensara que se esta trabajando con userList. En primer lugar separamos la información en train y test con el fin de poder aplicar tecnicas de reducción de dimensionalidad sin tener el bias de los datos de testeo.\n",
    "\n",
    "En primer lugar se buscara eliminar dimensionalidad utilizando correlación, a continuación se estandarizara la información y se ocuparan las tecnicas KNN, SVM y arboles para las predicciones y se utilizaran las metricas usales F1, precisión, recall y accuracy para entender cual metodo entrega una mejor clasificación.\n",
    "\n",
    "Se decide utilzar KNN y arboles pues se espra que sean capaces de generar modelos facilmente interpretativos, mientras que SVM se espera funcione bien dada su potencia. En caso de que no se tengan resultados satisfactorios o conlcusivos.\n",
    "\n",
    "\n",
    "Se eliminara dimensionalidad utilizando PCA y se replicara el metodo realizado anteriormente, con la idea de que quizas se redujo de una manera la dimensionalidad. Una vez comparado los resultados de este metodo entre si y con los anteriores, si es que sigue sin ser satisfactorio **AQUI NO SE QUIZAS NOS INTERESE HACER LO OTRO IGUALMENTE**\n",
    "\n",
    "\n",
    "En primer lugar se trabajara el dataset userList, se estudiaran las variables categoricas y dependiendo si entregan información relevante o no se eliminaran o se aplicara OHE o una transformación a número, con el fin de poder mantener una dimensionalidad baja, posteriormente se reducira la dimensionalidad estudiando las correlaciones y aplicando PCA, finalmente se va a predecir los valores con los metodos KNN, SVM, Arboles de decisión.  Si es que el metodo no funciona se estudiara el dataset completo sin reducción de dimensionalidad. \n",
    "\n",
    "En segundo lugar se trabajara el dataset userList y userAnimeList, se agregaran la información de este ultimo y se repitira el proceso sobre las variables categorias y la dimensionalidad que se realizo previamente. Por ultimo se juntaran los 3 datasets y se repetira el proceso.\n",
    "\n",
    "Se decide trabajar con los dataset de esta manera para intentar encontrar la menor cantidad posible de información que permite poder entender el gusto de los usuarios, además de esta manera se manitene la dimensionalidad de manera baja. Por otro lado se deciden utilizar las tecnias de correlacion y PCA para eliminar atributos pues la de correlación es una buena forma de mantener la interpretabilidad de la información y PCA porque es una manera sencilla de reducir la dimensionalidad. Por ultimo se deciden utilizar KNN pués se espera de una intuición de la forma en que estan agrupados los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimento 3 (Recomendador de anime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ta duro escribir esto\n",
    "\n",
    "Idea vaga para el cluster\n",
    "\n",
    "* Las variables categorias OHE o eliminarlas si es que no entregan información.\n",
    "* Hacer el cluster tal cual\n",
    "* Reducir dimensionalidad mediante correlacion hacer el cluster \n",
    "* Reducir dimensionalidad mediante PCA hacer el cluster \n",
    "* Juntar la información sobre episodios vistos\n",
    "* Hacer el cluster tal cual\n",
    "* Reducir dimensionalidad mediante correlacion hacer el cluster \n",
    "* Reducir dimensionalidad mediante PCA hacer el cluster \n",
    "* Juntar la información de los generos de anime que ha visto una persona a la base de datos de personas\n",
    "* Hacer el cluster tal cual\n",
    "* Reducir dimensionalidad mediante correlacion hacer el cluster \n",
    "* Reducir dimensionalidad mediante PCA hacer el cluster \n",
    "* Juntar la información sobre episodios vistos y Juntar la información de los generos de anime que ha visto una persona a la base de datos de personas\n",
    "* Hacer el cluster tal cual\n",
    "* Reducir dimensionalidad mediante correlacion hacer el cluster \n",
    "* Reducir dimensionalidad mediante PCA hacer el cluster \n",
    "\n",
    "Idea vaga para predecir genero\n",
    "* Las variables categorias OHE o eliminarlas si es que no entregan información.\n",
    "* Hacer la predicción tal cual\n",
    "* Reducir dimensionalidad mediante correlacion hacer la predicción \n",
    "* Reducir dimensionalidad mediante PCA hacer la predicción\n",
    "* Juntar la información sobre episodios vistos\n",
    "* Hacer  la predicción\n",
    "* Reducir dimensionalidad mediante correlacion hacer  la predicción\n",
    "* Reducir dimensionalidad mediante PCA hacer  la predicción\n",
    "* Juntar la información de los generos de anime que ha visto una persona a la base de datos de personas\n",
    "* Hacer la predicción\n",
    "* Reducir dimensionalidad mediante correlacion hacer la predicción\n",
    "* Reducir dimensionalidad mediante PCA hacer  la predicción\n",
    "* Juntar la información sobre episodios vistos y Juntar la información de los generos de anime que ha visto una persona a la base de datos de personas\n",
    "* Hacer  la predicción\n",
    "* Reducir dimensionalidad mediante correlacion hacer la predicción\n",
    "* Reducir dimensionalidad mediante PCA hacer  la predicción\n",
    "\n",
    "Idea vaga recomendador\n",
    "* idem a lo anterior, pero al conjunto de test quitarle un par de animes visto para ver si  el recomendador es capaz de recomendarlos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aqui agregar lo que haremos ahora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Codigo que oculta codigo\n",
    "\n",
    "# from IPython.display import HTML\n",
    "\n",
    "# HTML('''<script>\n",
    "# code_show=true; \n",
    "# function code_toggle() {\n",
    "#  if (code_show){\n",
    "#  $('div.input').hide();\n",
    "#  } else {\n",
    "#  $('div.input').show();\n",
    "#  }\n",
    "#  code_show = !code_show\n",
    "# } \n",
    "# $( document ).ready(code_toggle);\n",
    "# </script>\n",
    "# Por default el codigo en python esta oculto. Para activarlo / desactivarlo, click <a href=\"javascript:code_toggle()\">aqui</a>.''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTACIÓN DE LAS LIBRERÍAS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from IPython.display import display\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos preprocesados\n",
    "animeList = pd.read_csv('Datos/animeListPreprocesada.csv')\n",
    "userList = pd.read_csv('Datos/userListPreprocesada.csv')\n",
    "userAnimeList = pd.read_csv('Datos/animelists_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
